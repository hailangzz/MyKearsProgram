{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V5_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n",
    "\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, Flatten, Dense, Concatenate,Dropout\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "true_stand_data=np.load(r'.//data3//true_array.npy')\n",
    "false_stand_data=np.load(r'.//data3//false_array.npy')\n",
    "\n",
    "sample_num={'true_num':true_stand_data.shape[0],'false_num':false_stand_data.shape[0]}\n",
    "class_weight = {\n",
    "                0: (1 / sample_num['false_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2,\n",
    "                1: (1 / sample_num['true_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2\n",
    "                }\n",
    "\n",
    "\n",
    "true_sample_channel_1 = []\n",
    "true_sample_channel_1_left = []\n",
    "true_sample_channel_1_middle = []\n",
    "true_sample_channel_1_right = []\n",
    "\n",
    "\n",
    "false_sample_channel_1 = []\n",
    "false_sample_channel_1_left = []\n",
    "false_sample_channel_1_middle = []\n",
    "false_sample_channel_1_right = []\n",
    "\n",
    "for sample_number in range(true_stand_data.shape[0]):\n",
    "    true_sample_channel_1.append(copy.deepcopy(true_stand_data[sample_number,:,:,0]))\n",
    "    true_sample_channel_1_left.append(copy.deepcopy(true_stand_data[sample_number,-74:,:,0]))\n",
    "    true_sample_channel_1_middle.append(copy.deepcopy(true_stand_data[sample_number,-38:,:,0]))\n",
    "    true_sample_channel_1_right.append(copy.deepcopy(true_stand_data[sample_number,-20:,:,0]))\n",
    "\n",
    "for sample_number in range(false_stand_data.shape[0]):\n",
    "    false_sample_channel_1.append(copy.deepcopy(false_stand_data[sample_number,:,:,0]))\n",
    "    false_sample_channel_1_left.append(copy.deepcopy(false_stand_data[sample_number,-74:,:,0]))\n",
    "    false_sample_channel_1_middle.append(copy.deepcopy(false_stand_data[sample_number,-38:,:,0]))\n",
    "    false_sample_channel_1_right.append(copy.deepcopy(false_stand_data[sample_number,-20:,:,0]))\n",
    "    \n",
    "    \n",
    "combin_train_data1 = np.concatenate((true_sample_channel_1,false_sample_channel_1),axis=0)\n",
    "combin_train_data1_left = np.concatenate((true_sample_channel_1_left,false_sample_channel_1_left),axis=0)\n",
    "combin_train_data1_middle = np.concatenate((true_sample_channel_1_middle,false_sample_channel_1_middle),axis=0)\n",
    "combin_train_data1_right = np.concatenate((true_sample_channel_1_right,false_sample_channel_1_right),axis=0)\n",
    "\n",
    "combin_target_data= np.concatenate((np.ones((sample_num['true_num'],1)),np.zeros((sample_num['false_num'],1))),axis=0)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "combin_target_data=ohe.fit_transform(combin_target_data).toarray()\n",
    "\n",
    "# Model 1\n",
    "in_1 = Input(shape=(110,7))\n",
    "x_480_1 = GRU(units=480,return_sequences=True,input_shape=(110,7))(in_1)\n",
    "x_480_1 =Dropout(0.1)(x_480_1)\n",
    "x_48_1 = GRU(units=48)(x_480_1)\n",
    "\n",
    "x_240_1 = GRU(units=240,return_sequences=True,input_shape=(110,7))(in_1)\n",
    "x_240_1 =Dropout(0.1)(x_240_1)\n",
    "x_24_1 = GRU(units=24)(x_240_1)\n",
    "\n",
    "x_120_1 = GRU(units=120,return_sequences=True,input_shape=(110,7))(in_1)\n",
    "x_120_1 =Dropout(0.1)(x_120_1)\n",
    "x_12_1 = GRU(units=12)(x_120_1)\n",
    "\n",
    "x_1_concat = Concatenate(axis=-1)([x_48_1,x_24_1,x_12_1])\n",
    "x_1_concat_out = Dense(2, activation='softmax')(x_1_concat)\n",
    "\n",
    "###########################\n",
    "in_left = Input(shape=(74,7))\n",
    "x_480_left = GRU(units=240,return_sequences=True,input_shape=(74,7))(in_left)\n",
    "x_480_left =Dropout(0.1)(x_480_left)\n",
    "x_48_left = GRU(units=24)(x_480_left)\n",
    "\n",
    "x_240_left = GRU(units=120,return_sequences=True,input_shape=(74,7))(in_left)\n",
    "x_240_left =Dropout(0.1)(x_240_left)\n",
    "x_24_left = GRU(units=12)(x_240_left)\n",
    "\n",
    "x_120_left = GRU(units=60,return_sequences=True,input_shape=(74,7))(in_left)\n",
    "x_120_left =Dropout(0.1)(x_120_left)\n",
    "x_12_left = GRU(units=6)(x_120_left)\n",
    "\n",
    "x_left_concat = Concatenate(axis=-1)([x_48_left,x_24_left,x_12_left])\n",
    "x_left_concat_out = Dense(2, activation='softmax')(x_left_concat)\n",
    "\n",
    "#############################\n",
    "in_middle = Input(shape=(38,7))\n",
    "x_480_middle = GRU(units=120,return_sequences=True,input_shape=(38,7))(in_middle)\n",
    "x_480_middle =Dropout(0.1)(x_480_middle)\n",
    "x_48_middle = GRU(units=12)(x_480_middle)\n",
    "\n",
    "x_240_middle = GRU(units=60,return_sequences=True,input_shape=(38,7))(in_middle)\n",
    "x_240_middle =Dropout(0.1)(x_240_middle)\n",
    "x_24_middle = GRU(units=6)(x_240_middle)\n",
    "\n",
    "x_120_middle = GRU(units=30,return_sequences=True,input_shape=(38,7))(in_middle)\n",
    "x_120_middle =Dropout(0.1)(x_120_middle)\n",
    "x_12_middle = GRU(units=3)(x_120_middle)\n",
    "\n",
    "x_middle_concat = Concatenate(axis=-1)([x_48_middle,x_24_middle,x_12_middle])\n",
    "x_middle_concat_out = Dense(2, activation='softmax')(x_middle_concat)\n",
    "\n",
    "\n",
    "###########################\n",
    "in_right = Input(shape=(20,7))\n",
    "x_480_right = GRU(units=60,return_sequences=True,input_shape=(20,7))(in_right)\n",
    "x_480_right =Dropout(0.1)(x_480_right)\n",
    "x_48_right = GRU(units=6)(x_480_right)\n",
    "\n",
    "x_240_right = GRU(units=30,return_sequences=True,input_shape=(20,7))(in_right)\n",
    "x_240_right =Dropout(0.1)(x_240_right)\n",
    "x_24_right = GRU(units=3)(x_240_right)\n",
    "\n",
    "x_120_right = GRU(units=15,return_sequences=True,input_shape=(20,7))(in_right)\n",
    "x_120_right =Dropout(0.1)(x_120_right)\n",
    "x_12_right = GRU(units=2)(x_120_right)\n",
    "\n",
    "x_right_concat = Concatenate(axis=-1)([x_48_right,x_24_right,x_12_right])\n",
    "x_right_concat_out = Dense(2, activation='softmax')(x_right_concat)\n",
    "\n",
    "total_out_concat = Concatenate(axis=-1)([x_1_concat_out,x_left_concat_out,x_middle_concat_out,x_right_concat_out])\n",
    "model_final_dense_out = Dense(2, activation='softmax')(total_out_concat)\n",
    "\n",
    "model = Model(inputs=[in_1,in_left,in_middle,in_right], outputs=model_final_dense_out)\n",
    "print(model.summary())\n",
    "\n",
    "import os\n",
    "if 'GRU_predict_v5.h5' in os.listdir('./'):\n",
    "    model = load_model(\"./GRU_predict_v5.h5\")\n",
    "\n",
    "callbacks_list = [    \n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='accuracy', \n",
    "        patience=30\n",
    "    ),\n",
    "    # 保存模型\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'GRU_predict_v5.h5', \n",
    "    monitor='loss', \n",
    "    save_best_only=True),\n",
    "    \n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', \n",
    "        factor=0.9,\n",
    "        patience=5, \n",
    "        mode='auto',\n",
    "        min_lr=0.00003)\n",
    "]\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', #continu together\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy']\n",
    "             \n",
    "             )\n",
    "\n",
    "model.fit(x=[combin_train_data1,combin_train_data1_left,combin_train_data1_middle,combin_train_data1_right],\n",
    "          y=combin_target_data,\n",
    "          batch_size=120,\n",
    "          epochs=100,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          class_weight=class_weight,\n",
    "          callbacks=callbacks_list      \n",
    "         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V5_2  收敛还不错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n",
    "\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, Flatten, Dense, Concatenate,Dropout\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "true_stand_data=np.load(r'.//data3//true_array.npy')\n",
    "false_stand_data=np.load(r'.//data3//false_array.npy')\n",
    "\n",
    "sample_num={'true_num':true_stand_data.shape[0],'false_num':false_stand_data.shape[0]}\n",
    "class_weight = {\n",
    "                0: (1 / sample_num['false_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2,\n",
    "                1: (1 / sample_num['true_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2\n",
    "                }\n",
    "\n",
    "\n",
    "true_sample_channel_1 = []\n",
    "true_sample_channel_1_left = []\n",
    "true_sample_channel_1_middle = []\n",
    "true_sample_channel_1_right = []\n",
    "\n",
    "\n",
    "false_sample_channel_1 = []\n",
    "false_sample_channel_1_left = []\n",
    "false_sample_channel_1_middle = []\n",
    "false_sample_channel_1_right = []\n",
    "\n",
    "for sample_number in range(true_stand_data.shape[0]):\n",
    "    true_sample_channel_1.append(copy.deepcopy(true_stand_data[sample_number,:,:,0]))\n",
    "    true_sample_channel_1_left.append(copy.deepcopy(true_stand_data[sample_number,-74:,:,0]))\n",
    "    true_sample_channel_1_middle.append(copy.deepcopy(true_stand_data[sample_number,-38:,:,0]))\n",
    "    true_sample_channel_1_right.append(copy.deepcopy(true_stand_data[sample_number,-20:,:,0]))\n",
    "\n",
    "for sample_number in range(false_stand_data.shape[0]):\n",
    "    false_sample_channel_1.append(copy.deepcopy(false_stand_data[sample_number,:,:,0]))\n",
    "    false_sample_channel_1_left.append(copy.deepcopy(false_stand_data[sample_number,-74:,:,0]))\n",
    "    false_sample_channel_1_middle.append(copy.deepcopy(false_stand_data[sample_number,-38:,:,0]))\n",
    "    false_sample_channel_1_right.append(copy.deepcopy(false_stand_data[sample_number,-20:,:,0]))\n",
    "    \n",
    "    \n",
    "combin_train_data1 = np.concatenate((true_sample_channel_1,false_sample_channel_1),axis=0)\n",
    "combin_train_data1_left = np.concatenate((true_sample_channel_1_left,false_sample_channel_1_left),axis=0)\n",
    "combin_train_data1_middle = np.concatenate((true_sample_channel_1_middle,false_sample_channel_1_middle),axis=0)\n",
    "combin_train_data1_right = np.concatenate((true_sample_channel_1_right,false_sample_channel_1_right),axis=0)\n",
    "\n",
    "combin_target_data= np.concatenate((np.ones((sample_num['true_num'],1)),np.zeros((sample_num['false_num'],1))),axis=0)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "combin_target_data=ohe.fit_transform(combin_target_data).toarray()\n",
    "\n",
    "# Model 1\n",
    "in_1 = Input(shape=(110,7))\n",
    "x_480_1 = GRU(units=480,return_sequences=True,input_shape=(110,7))(in_1)\n",
    "x_480_1 =Dropout(0.1)(x_480_1)\n",
    "x_48_1 = GRU(units=48)(x_480_1)\n",
    "\n",
    "x_240_1 = GRU(units=240,return_sequences=True,input_shape=(110,7))(in_1)\n",
    "x_240_1 =Dropout(0.1)(x_240_1)\n",
    "x_24_1 = GRU(units=24)(x_240_1)\n",
    "\n",
    "x_1_concat = Concatenate(axis=-1)([x_48_1,x_24_1])\n",
    "x_1_concat_out = Dense(2, activation='softmax')(x_1_concat)\n",
    "\n",
    "###########################\n",
    "in_left = Input(shape=(74,7))\n",
    "x_480_left = GRU(units=240,return_sequences=True,input_shape=(74,7))(in_left)\n",
    "x_480_left =Dropout(0.1)(x_480_left)\n",
    "x_48_left = GRU(units=24)(x_480_left)\n",
    "\n",
    "x_240_left = GRU(units=120,return_sequences=True,input_shape=(74,7))(in_left)\n",
    "x_240_left =Dropout(0.1)(x_240_left)\n",
    "x_24_left = GRU(units=12)(x_240_left)\n",
    "\n",
    "x_left_concat = Concatenate(axis=-1)([x_48_left,x_24_left])\n",
    "x_left_concat_out = Dense(2, activation='softmax')(x_left_concat)\n",
    "\n",
    "#############################\n",
    "in_middle = Input(shape=(38,7))\n",
    "x_480_middle = GRU(units=120,return_sequences=True,input_shape=(38,7))(in_middle)\n",
    "x_480_middle =Dropout(0.1)(x_480_middle)\n",
    "x_48_middle = GRU(units=12)(x_480_middle)\n",
    "\n",
    "x_240_middle = GRU(units=60,return_sequences=True,input_shape=(38,7))(in_middle)\n",
    "x_240_middle =Dropout(0.1)(x_240_middle)\n",
    "x_24_middle = GRU(units=6)(x_240_middle)\n",
    "\n",
    "x_middle_concat = Concatenate(axis=-1)([x_48_middle,x_24_middle])\n",
    "x_middle_concat_out = Dense(2, activation='softmax')(x_middle_concat)\n",
    "\n",
    "\n",
    "###########################\n",
    "in_right = Input(shape=(20,7))\n",
    "x_480_right = GRU(units=60,return_sequences=True,input_shape=(20,7))(in_right)\n",
    "x_480_right =Dropout(0.1)(x_480_right)\n",
    "x_48_right = GRU(units=6)(x_480_right)\n",
    "\n",
    "x_240_right = GRU(units=30,return_sequences=True,input_shape=(20,7))(in_right)\n",
    "x_240_right =Dropout(0.1)(x_240_right)\n",
    "x_24_right = GRU(units=3)(x_240_right)\n",
    "\n",
    "x_right_concat = Concatenate(axis=-1)([x_48_right,x_24_right])\n",
    "x_right_concat_out = Dense(2, activation='softmax')(x_right_concat)\n",
    "\n",
    "total_out_concat = Concatenate(axis=-1)([x_1_concat_out,x_left_concat_out,x_middle_concat_out,x_right_concat_out])\n",
    "model_final_dense_out = Dense(2, activation='softmax')(total_out_concat)\n",
    "\n",
    "model = Model(inputs=[in_1,in_left,in_middle,in_right], outputs=model_final_dense_out)\n",
    "print(model.summary())\n",
    "\n",
    "import os\n",
    "if 'GRU_predict_v5.h5' in os.listdir('./'):\n",
    "    model = load_model(\"./GRU_predict_v5.h5\")\n",
    "\n",
    "callbacks_list = [    \n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='accuracy', \n",
    "        patience=30\n",
    "    ),\n",
    "    # 保存模型\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'GRU_predict_v5.h5', \n",
    "    monitor='loss', \n",
    "    save_best_only=True),\n",
    "    \n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', \n",
    "        factor=0.8,\n",
    "        patience=5, \n",
    "        mode='auto',\n",
    "        min_lr=0.00003)\n",
    "]\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', #continu together\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy']\n",
    "             \n",
    "             )\n",
    "\n",
    "model.fit(x=[combin_train_data1,combin_train_data1_left,combin_train_data1_middle,combin_train_data1_right],\n",
    "          y=combin_target_data,\n",
    "          batch_size=360,\n",
    "          epochs=100,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          class_weight=class_weight,\n",
    "          callbacks=callbacks_list      \n",
    "         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V5_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n",
    "\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, Flatten, Dense, Concatenate,Dropout\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "true_stand_data=np.load(r'.//data3//true_array.npy')\n",
    "false_stand_data=np.load(r'.//data3//false_array.npy')\n",
    "\n",
    "sample_num={'true_num':true_stand_data.shape[0],'false_num':false_stand_data.shape[0]}\n",
    "class_weight = {\n",
    "                0: (1 / sample_num['false_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2,\n",
    "                1: (1 / sample_num['true_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2\n",
    "                }\n",
    "\n",
    "\n",
    "true_sample_channel_1 = []\n",
    "true_sample_channel_1_left = []\n",
    "true_sample_channel_1_middle = []\n",
    "true_sample_channel_1_right = []\n",
    "\n",
    "\n",
    "false_sample_channel_1 = []\n",
    "false_sample_channel_1_left = []\n",
    "false_sample_channel_1_middle = []\n",
    "false_sample_channel_1_right = []\n",
    "\n",
    "for sample_number in range(true_stand_data.shape[0]):\n",
    "    true_sample_channel_1.append(copy.deepcopy(true_stand_data[sample_number,:,:,0]))\n",
    "    true_sample_channel_1_left.append(copy.deepcopy(true_stand_data[sample_number,-74:,:,0]))\n",
    "    true_sample_channel_1_middle.append(copy.deepcopy(true_stand_data[sample_number,-38:,:,0]))\n",
    "    true_sample_channel_1_right.append(copy.deepcopy(true_stand_data[sample_number,-20:,:,0]))\n",
    "\n",
    "for sample_number in range(false_stand_data.shape[0]):\n",
    "    false_sample_channel_1.append(copy.deepcopy(false_stand_data[sample_number,:,:,0]))\n",
    "    false_sample_channel_1_left.append(copy.deepcopy(false_stand_data[sample_number,-74:,:,0]))\n",
    "    false_sample_channel_1_middle.append(copy.deepcopy(false_stand_data[sample_number,-38:,:,0]))\n",
    "    false_sample_channel_1_right.append(copy.deepcopy(false_stand_data[sample_number,-20:,:,0]))\n",
    "    \n",
    "    \n",
    "combin_train_data1 = np.concatenate((true_sample_channel_1,false_sample_channel_1),axis=0)\n",
    "combin_train_data1_left = np.concatenate((true_sample_channel_1_left,false_sample_channel_1_left),axis=0)\n",
    "combin_train_data1_middle = np.concatenate((true_sample_channel_1_middle,false_sample_channel_1_middle),axis=0)\n",
    "combin_train_data1_right = np.concatenate((true_sample_channel_1_right,false_sample_channel_1_right),axis=0)\n",
    "\n",
    "combin_target_data= np.concatenate((np.ones((sample_num['true_num'],1)),np.zeros((sample_num['false_num'],1))),axis=0)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "combin_target_data=ohe.fit_transform(combin_target_data).toarray()\n",
    "\n",
    "# Model 1\n",
    "in_1 = Input(shape=(110,7))\n",
    "x_480_1 = GRU(units=480,return_sequences=True,input_shape=(110,7))(in_1)\n",
    "x_480_1 =Dropout(0.1)(x_480_1)\n",
    "x_48_1 = GRU(units=48)(x_480_1)\n",
    "\n",
    "x_240_1 = GRU(units=240,return_sequences=True,input_shape=(110,7))(in_1)\n",
    "x_240_1 =Dropout(0.1)(x_240_1)\n",
    "x_24_1 = GRU(units=24)(x_240_1)\n",
    "\n",
    "x_1_concat = Concatenate(axis=-1)([x_48_1,x_24_1])\n",
    "x_1_concat_out = Dense(3, activation='tanh')(x_1_concat)\n",
    "\n",
    "###########################\n",
    "in_left = Input(shape=(74,7))\n",
    "x_480_left = GRU(units=240,return_sequences=True,input_shape=(74,7))(in_left)\n",
    "x_480_left =Dropout(0.1)(x_480_left)\n",
    "x_48_left = GRU(units=24)(x_480_left)\n",
    "\n",
    "x_240_left = GRU(units=120,return_sequences=True,input_shape=(74,7))(in_left)\n",
    "x_240_left =Dropout(0.1)(x_240_left)\n",
    "x_24_left = GRU(units=12)(x_240_left)\n",
    "\n",
    "x_left_concat = Concatenate(axis=-1)([x_48_left,x_24_left])\n",
    "x_left_concat_out = Dense(3, activation='tanh')(x_left_concat)\n",
    "\n",
    "#############################\n",
    "in_middle = Input(shape=(38,7))\n",
    "x_480_middle = GRU(units=120,return_sequences=True,input_shape=(38,7))(in_middle)\n",
    "x_480_middle =Dropout(0.1)(x_480_middle)\n",
    "x_48_middle = GRU(units=12)(x_480_middle)\n",
    "\n",
    "x_240_middle = GRU(units=60,return_sequences=True,input_shape=(38,7))(in_middle)\n",
    "x_240_middle =Dropout(0.1)(x_240_middle)\n",
    "x_24_middle = GRU(units=6)(x_240_middle)\n",
    "\n",
    "x_middle_concat = Concatenate(axis=-1)([x_48_middle,x_24_middle])\n",
    "x_middle_concat_out = Dense(3, activation='tanh')(x_middle_concat)\n",
    "\n",
    "\n",
    "###########################\n",
    "in_right = Input(shape=(20,7))\n",
    "x_480_right = GRU(units=60,return_sequences=True,input_shape=(20,7))(in_right)\n",
    "x_480_right =Dropout(0.1)(x_480_right)\n",
    "x_48_right = GRU(units=6)(x_480_right)\n",
    "\n",
    "x_240_right = GRU(units=30,return_sequences=True,input_shape=(20,7))(in_right)\n",
    "x_240_right =Dropout(0.1)(x_240_right)\n",
    "x_24_right = GRU(units=3)(x_240_right)\n",
    "\n",
    "x_right_concat = Concatenate(axis=-1)([x_48_right,x_24_right])\n",
    "x_right_concat_out = Dense(3, activation='tanh')(x_right_concat)\n",
    "\n",
    "total_out_concat = Concatenate(axis=-1)([x_1_concat_out,x_left_concat_out,x_middle_concat_out,x_right_concat_out])\n",
    "model_final_dense_out = Dense(2, activation='softmax')(total_out_concat)\n",
    "\n",
    "model = Model(inputs=[in_1,in_left,in_middle,in_right], outputs=model_final_dense_out)\n",
    "print(model.summary())\n",
    "\n",
    "import os\n",
    "if 'GRU_predict_v5.h5' in os.listdir('./'):\n",
    "    model = load_model(\"./GRU_predict_v5.h5\")\n",
    "\n",
    "callbacks_list = [    \n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='accuracy', \n",
    "        patience=30\n",
    "    ),\n",
    "    # 保存模型\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'GRU_predict_v5.h5', \n",
    "    monitor='loss', \n",
    "    save_best_only=True),\n",
    "    \n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', \n",
    "        factor=0.8,\n",
    "        patience=5, \n",
    "        mode='auto',\n",
    "        min_lr=0.00003)\n",
    "]\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', #continu together\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy']\n",
    "             \n",
    "             )\n",
    "\n",
    "model.fit(x=[combin_train_data1,combin_train_data1_left,combin_train_data1_middle,combin_train_data1_right],\n",
    "          y=combin_target_data,\n",
    "          batch_size=360,\n",
    "          epochs=100,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          class_weight=class_weight,\n",
    "          callbacks=callbacks_list      \n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5,6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
