{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Sequential, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n",
    "\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, Flatten, Dense, Concatenate,Dropout\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "true_stand_data=np.load(r'.//data3//true_array.npy')\n",
    "false_stand_data=np.load(r'.//data3//false_array.npy')\n",
    "\n",
    "sample_num={'true_num':true_stand_data.shape[0],'false_num':false_stand_data.shape[0]}\n",
    "class_weight = {\n",
    "                0: (1 / sample_num['false_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2,\n",
    "                1: (1 / sample_num['true_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2\n",
    "                }\n",
    "\n",
    "\n",
    "true_sample_channel_1 = []\n",
    "true_sample_channel_2 = []\n",
    "\n",
    "\n",
    "false_sample_channel_1 = []\n",
    "false_sample_channel_2 = []\n",
    "\n",
    "for sample_number in range(true_stand_data.shape[0]):\n",
    "    true_sample_channel_1.append(copy.deepcopy(true_stand_data[sample_number,:,:,0]))\n",
    "#     true_sample_channel_2.append(copy.deepcopy(true_stand_data[sample_number,:,:,1]))\n",
    "\n",
    "for sample_number in range(false_stand_data.shape[0]):\n",
    "    false_sample_channel_1.append(copy.deepcopy(false_stand_data[sample_number,:,:,0]))\n",
    "#     false_sample_channel_2.append(copy.deepcopy(false_stand_data[sample_number,:,:,1]))\n",
    "\n",
    "combin_train_data1 = np.concatenate((true_sample_channel_1,false_sample_channel_1),axis=0)\n",
    "# combin_train_data2 = np.concatenate((true_sample_channel_2,false_sample_channel_2),axis=0)\n",
    "\n",
    "combin_target_data= np.concatenate((np.ones((sample_num['true_num'],1)),np.zeros((sample_num['false_num'],1))),axis=0)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "combin_target_data=ohe.fit_transform(combin_target_data).toarray()\n",
    "\n",
    "# Model 1\n",
    "in1 = Input(shape=(110,7))\n",
    "x_7_left = GRU(units=7,input_shape=(110,21))(in1)\n",
    "x_21_left = GRU(units=21,input_shape=(110,21))(in1)\n",
    "x_64_left = GRU(units=64,input_shape=(110,21))(in1)\n",
    "x_192_left = GRU(units=192,input_shape=(110,21))(in1)\n",
    "x_576_left = GRU(units=576,input_shape=(110,21))(in1)\n",
    "x_1024_left = GRU(units=1024,input_shape=(110,21))(in1)\n",
    "\n",
    "x_left_concat = Concatenate(axis=-1)([x_7_left,x_21_left,x_64_left,x_192_left,x_576_left,x_1024_left])\n",
    "\n",
    "model_final_dense_1 = Dense(100, activation='relu')(x_left_concat)\n",
    "model_final_dense_1 = Dropout(0.2)(model_final_dense_1)\n",
    "model_final_dense_out = Dense(2, activation='softmax')(model_final_dense_1)\n",
    "\n",
    "\n",
    "model = Model(inputs=[in1], outputs=model_final_dense_out)\n",
    "print(model.summary())\n",
    "\n",
    "import os\n",
    "if 'GRU_predict.h5' in os.listdir('./'):\n",
    "    model = load_model(\"./GRU_predict.h5\")\n",
    "\n",
    "callbacks_list = [\n",
    "    \n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='accuracy', \n",
    "        patience=3 \n",
    "    ),\n",
    "    # 保存模型\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'GRU_predict.h5', \n",
    "    monitor='loss', \n",
    "    save_best_only=True) \n",
    "]\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', #continu together\n",
    "#               optimizer='adam',\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "              metrics=['accuracy']\n",
    "             \n",
    "             )\n",
    "\n",
    "model.fit(x=combin_train_data1,\n",
    "          y=combin_target_data,\n",
    "          batch_size=120, \n",
    "          epochs=100,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          class_weight=class_weight,\n",
    "          callbacks=callbacks_list      \n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
