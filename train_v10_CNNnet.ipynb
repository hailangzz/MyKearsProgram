{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n",
    "\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D,Convolution1D,MaxPooling1D, Flatten, Dense, Concatenate,Dropout\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_stand_data=np.load(r'F:\\\\深度学习模型项目\\\\神经网络GRU模型\\\\data3\\\\data3//true_array.npy')\n",
    "false_stand_data=np.load(r'F:\\\\深度学习模型项目\\\\神经网络GRU模型\\\\data3\\\\data3//false_array.npy')\n",
    "\n",
    "true_stand_data=true_stand_data[:,:,:,0]\n",
    "false_stand_data=false_stand_data[:,:,:,0]\n",
    "\n",
    "# true_stand_data=true_stand_data.swapaxes(1, 2)\n",
    "# false_stand_data=false_stand_data.swapaxes(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25230, 110, 7)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_stand_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num={'true_num':true_stand_data.shape[0],'false_num':false_stand_data.shape[0]}\n",
    "class_weight = {\n",
    "                0: (1 / sample_num['false_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2,\n",
    "                1: (1 / sample_num['true_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_sample_channel_1 = []\n",
    "true_sample_channel_2 = []\n",
    "true_sample_channel_3 = []\n",
    "\n",
    "false_sample_channel_1 = []\n",
    "false_sample_channel_2 = []\n",
    "false_sample_channel_3 = []\n",
    "\n",
    "\n",
    "for sample_number in range(true_stand_data.shape[0]):\n",
    "    true_sample_channel_1.append(copy.deepcopy(true_stand_data[sample_number,:,1]))\n",
    "    true_sample_channel_2.append(copy.deepcopy(true_stand_data[sample_number,:,2]))\n",
    "    true_sample_channel_3.append(copy.deepcopy(true_stand_data[sample_number,:,6]))\n",
    "    \n",
    "for sample_number in range(false_stand_data.shape[0]):\n",
    "    false_sample_channel_1.append(copy.deepcopy(false_stand_data[sample_number,:,1]))\n",
    "    false_sample_channel_2.append(copy.deepcopy(false_stand_data[sample_number,:,2]))\n",
    "    false_sample_channel_3.append(copy.deepcopy(false_stand_data[sample_number,:,6]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110,)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_sample_channel_3[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110,)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_sample_channel_2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "combin_train_data1 = np.concatenate((true_sample_channel_1,false_sample_channel_1),axis=0)\n",
    "combin_train_data2 = np.concatenate((true_sample_channel_2,false_sample_channel_2),axis=0)\n",
    "combin_train_data3 = np.concatenate((true_sample_channel_3,false_sample_channel_3),axis=0)\n",
    "\n",
    "combin_target_data= np.concatenate((np.ones((sample_num['true_num'],1)),np.zeros((sample_num['false_num'],1))),axis=0)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "combin_target_data=ohe.fit_transform(combin_target_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110,)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_sample_channel_1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_115\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_90 (InputLayer)           [(None, 110, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_91 (InputLayer)           [(None, 110, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_51 (InputLayer)           [(None, 110, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_616 (Conv1D)             (None, 110, 4)       16          input_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_624 (Conv1D)             (None, 110, 4)       16          input_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_632 (Conv1D)             (None, 110, 4)       16          input_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_617 (Conv1D)             (None, 110, 4)       52          conv1d_616[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_625 (Conv1D)             (None, 110, 4)       52          conv1d_624[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_633 (Conv1D)             (None, 110, 4)       52          conv1d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_302 (MaxPooling1D (None, 55, 4)        0           conv1d_617[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_306 (MaxPooling1D (None, 55, 4)        0           conv1d_625[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_310 (MaxPooling1D (None, 55, 4)        0           conv1d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_618 (Conv1D)             (None, 55, 8)        104         max_pooling1d_302[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_626 (Conv1D)             (None, 55, 8)        104         max_pooling1d_306[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_634 (Conv1D)             (None, 55, 8)        104         max_pooling1d_310[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_619 (Conv1D)             (None, 55, 8)        200         conv1d_618[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_627 (Conv1D)             (None, 55, 8)        200         conv1d_626[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_635 (Conv1D)             (None, 55, 8)        200         conv1d_634[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_303 (MaxPooling1D (None, 27, 8)        0           conv1d_619[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_307 (MaxPooling1D (None, 27, 8)        0           conv1d_627[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_311 (MaxPooling1D (None, 27, 8)        0           conv1d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_620 (Conv1D)             (None, 27, 16)       400         max_pooling1d_303[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_628 (Conv1D)             (None, 27, 16)       400         max_pooling1d_307[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_636 (Conv1D)             (None, 27, 16)       400         max_pooling1d_311[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_621 (Conv1D)             (None, 27, 16)       784         conv1d_620[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_629 (Conv1D)             (None, 27, 16)       784         conv1d_628[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_637 (Conv1D)             (None, 27, 16)       784         conv1d_636[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_304 (MaxPooling1D (None, 13, 16)       0           conv1d_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_308 (MaxPooling1D (None, 13, 16)       0           conv1d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_312 (MaxPooling1D (None, 13, 16)       0           conv1d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_622 (Conv1D)             (None, 13, 32)       1568        max_pooling1d_304[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_630 (Conv1D)             (None, 13, 32)       1568        max_pooling1d_308[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_638 (Conv1D)             (None, 13, 32)       1568        max_pooling1d_312[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_623 (Conv1D)             (None, 13, 32)       3104        conv1d_622[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_631 (Conv1D)             (None, 13, 32)       3104        conv1d_630[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_639 (Conv1D)             (None, 13, 32)       3104        conv1d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_305 (MaxPooling1D (None, 6, 32)        0           conv1d_623[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_309 (MaxPooling1D (None, 6, 32)        0           conv1d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_313 (MaxPooling1D (None, 6, 32)        0           conv1d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_58 (Flatten)            (None, 192)          0           max_pooling1d_305[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_59 (Flatten)            (None, 192)          0           max_pooling1d_309[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_60 (Flatten)            (None, 192)          0           max_pooling1d_313[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 576)          0           flatten_58[0][0]                 \n",
      "                                                                 flatten_59[0][0]                 \n",
      "                                                                 flatten_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 100)          57700       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 2)            202         dense_44[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 76,586\n",
      "Trainable params: 76,586\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 798/5408 [===>..........................] - ETA: 38s - loss: 0.6692 - accuracy: 0.5991"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-166-89a50bae3209>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m           \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m           \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m          )\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "in_1 = Input(shape=(110,1))\n",
    "C_1 = Convolution1D(filters=4,kernel_size=3,input_shape=(110,1),padding='same')(in_1)\n",
    "C_1 = Convolution1D(filters=4,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "C_1 = Convolution1D(filters=8,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = Convolution1D(filters=8,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "C_1 = Convolution1D(filters=16,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = Convolution1D(filters=16,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "C_1 = Convolution1D(filters=32,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = Convolution1D(filters=32,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "C_1 = Flatten()(C_1)\n",
    "\n",
    "# # Model 1\n",
    "in_2 = Input(shape=(110,1))\n",
    "C_2 = Convolution1D(filters=4,kernel_size=3,input_shape=(110,1),padding='same')(in_2)\n",
    "C_2 = Convolution1D(filters=4,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "\n",
    "C_2 = Convolution1D(filters=8,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = Convolution1D(filters=8,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "\n",
    "C_2 = Convolution1D(filters=16,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = Convolution1D(filters=16,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "\n",
    "C_2 = Convolution1D(filters=32,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = Convolution1D(filters=32,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "C_2 = Flatten()(C_2)\n",
    "\n",
    "# in_3 = Input(shape=(110,1))\n",
    "C_3 = Convolution1D(filters=4,kernel_size=3,input_shape=(110,1),padding='same')(in_3)\n",
    "C_3 = Convolution1D(filters=4,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "\n",
    "C_3 = Convolution1D(filters=8,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = Convolution1D(filters=8,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "\n",
    "C_3 = Convolution1D(filters=16,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = Convolution1D(filters=16,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "\n",
    "C_3 = Convolution1D(filters=32,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = Convolution1D(filters=32,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "C_3 = Flatten()(C_3)\n",
    "\n",
    "x_middle_concat = Concatenate(axis=-1)([C_1,C_2,C_3])\n",
    "x_middle_concat = Dense(100, activation='tanh')(x_middle_concat)\n",
    "model_final_dense_out = Dense(2, activation='softmax')(x_middle_concat)\n",
    "\n",
    "\n",
    "model = Model(inputs=[in_1,in_2,in_3], outputs=model_final_dense_out)\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "if 'GRU_predict_v10_2.h5' in os.listdir('./'):\n",
    "    model = load_model(\"./GRU_predict_v10_2.h5\")\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='accuracy', \n",
    "        patience=30\n",
    "    ),\n",
    "    # 保存模型\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'GRU_predict_v10_2.h5', \n",
    "    monitor='loss', \n",
    "    save_best_only=True),\n",
    "    \n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', \n",
    "        factor=0.8,\n",
    "        patience=5, \n",
    "        mode='auto',\n",
    "        min_lr=0.00003)\n",
    "]\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', #continu together\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy']\n",
    "             \n",
    "             )\n",
    "\n",
    "model.fit(x=[combin_train_data1,combin_train_data2,combin_train_data3],\n",
    "          y=combin_target_data,\n",
    "          batch_size=36,\n",
    "          epochs=100,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          class_weight=class_weight,\n",
    "          callbacks=callbacks_list \n",
    "         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v_10_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_127\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_102 (InputLayer)          [(None, 110, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_103 (InputLayer)          [(None, 110, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_51 (InputLayer)           [(None, 110, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_760 (Conv1D)             (None, 110, 4)       16          input_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_768 (Conv1D)             (None, 110, 4)       16          input_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_776 (Conv1D)             (None, 110, 4)       16          input_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_761 (Conv1D)             (None, 110, 4)       52          conv1d_760[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_769 (Conv1D)             (None, 110, 4)       52          conv1d_768[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_777 (Conv1D)             (None, 110, 4)       52          conv1d_776[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_365 (MaxPooling1D (None, 55, 4)        0           conv1d_761[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_368 (MaxPooling1D (None, 55, 4)        0           conv1d_769[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_371 (MaxPooling1D (None, 55, 4)        0           conv1d_777[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_762 (Conv1D)             (None, 55, 8)        104         max_pooling1d_365[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_770 (Conv1D)             (None, 55, 8)        104         max_pooling1d_368[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_778 (Conv1D)             (None, 55, 8)        104         max_pooling1d_371[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_763 (Conv1D)             (None, 55, 8)        200         conv1d_762[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_771 (Conv1D)             (None, 55, 8)        200         conv1d_770[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_779 (Conv1D)             (None, 55, 8)        200         conv1d_778[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_366 (MaxPooling1D (None, 27, 8)        0           conv1d_763[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_369 (MaxPooling1D (None, 27, 8)        0           conv1d_771[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_372 (MaxPooling1D (None, 27, 8)        0           conv1d_779[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_764 (Conv1D)             (None, 27, 16)       400         max_pooling1d_366[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_772 (Conv1D)             (None, 27, 16)       400         max_pooling1d_369[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_780 (Conv1D)             (None, 27, 16)       400         max_pooling1d_372[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_765 (Conv1D)             (None, 27, 16)       784         conv1d_764[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_773 (Conv1D)             (None, 27, 16)       784         conv1d_772[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_781 (Conv1D)             (None, 27, 16)       784         conv1d_780[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_367 (MaxPooling1D (None, 13, 16)       0           conv1d_765[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_370 (MaxPooling1D (None, 13, 16)       0           conv1d_773[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_373 (MaxPooling1D (None, 13, 16)       0           conv1d_781[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_766 (Conv1D)             (None, 13, 32)       1568        max_pooling1d_367[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_774 (Conv1D)             (None, 13, 32)       1568        max_pooling1d_370[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_782 (Conv1D)             (None, 13, 32)       1568        max_pooling1d_373[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_767 (Conv1D)             (None, 13, 32)       3104        conv1d_766[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_775 (Conv1D)             (None, 13, 32)       3104        conv1d_774[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_783 (Conv1D)             (None, 13, 32)       3104        conv1d_782[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 13, 96)       0           conv1d_767[0][0]                 \n",
      "                                                                 conv1d_775[0][0]                 \n",
      "                                                                 conv1d_783[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     (None, 13, 288)      333504      concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gru_5 (GRU)                     (None, 100)          117000      gru_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 2)            202         gru_5[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 469,390\n",
      "Trainable params: 469,390\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "in_1 = Input(shape=(110,1))\n",
    "C_1 = Convolution1D(filters=4,kernel_size=3,input_shape=(110,1),padding='same')(in_1)\n",
    "C_1 = Convolution1D(filters=4,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "C_1 = Convolution1D(filters=8,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = Convolution1D(filters=8,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "C_1 = Convolution1D(filters=16,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = Convolution1D(filters=16,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "C_1 = Convolution1D(filters=32,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = Convolution1D(filters=32,kernel_size=3,padding='same')(C_1)\n",
    "# C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "# C_1 = Flatten()(C_1)\n",
    "\n",
    "# # Model 1\n",
    "in_2 = Input(shape=(110,1))\n",
    "C_2 = Convolution1D(filters=4,kernel_size=3,input_shape=(110,1),padding='same')(in_2)\n",
    "C_2 = Convolution1D(filters=4,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "\n",
    "C_2 = Convolution1D(filters=8,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = Convolution1D(filters=8,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "\n",
    "C_2 = Convolution1D(filters=16,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = Convolution1D(filters=16,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "\n",
    "C_2 = Convolution1D(filters=32,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = Convolution1D(filters=32,kernel_size=3,padding='same')(C_2)\n",
    "# C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "# C_2 = Flatten()(C_2)\n",
    "\n",
    "# in_3 = Input(shape=(110,1))\n",
    "C_3 = Convolution1D(filters=4,kernel_size=3,input_shape=(110,1),padding='same')(in_3)\n",
    "C_3 = Convolution1D(filters=4,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "\n",
    "C_3 = Convolution1D(filters=8,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = Convolution1D(filters=8,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "\n",
    "C_3 = Convolution1D(filters=16,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = Convolution1D(filters=16,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "\n",
    "C_3 = Convolution1D(filters=32,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = Convolution1D(filters=32,kernel_size=3,padding='same')(C_3)\n",
    "# C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "# C_3 = Flatten()(C_3)\n",
    "\n",
    "x_middle_concat = Concatenate(axis=-1)([C_1,C_2,C_3])\n",
    "\n",
    "x_middle_concat = GRU(units=288,return_sequences=True)(x_middle_concat)\n",
    "x_middle_concat = GRU(units=100)(x_middle_concat)\n",
    "# x_middle_concat = Dense(100, activation='tanh')(x_middle_concat)\n",
    "# x_middle_concat = Flatten()(x_middle_concat)\n",
    "model_final_dense_out = Dense(2, activation='softmax')(x_middle_concat)\n",
    "\n",
    "\n",
    "model = Model(inputs=[in_1,in_2,in_3], outputs=model_final_dense_out)\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5408/5408 [==============================] - 164s 30ms/step - loss: 0.6407 - accuracy: 0.6516\n",
      "Epoch 2/100\n",
      "5408/5408 [==============================] - 170s 31ms/step - loss: 0.5891 - accuracy: 0.7075\n",
      "Epoch 3/100\n",
      "5408/5408 [==============================] - 167s 31ms/step - loss: 0.5646 - accuracy: 0.7266\n",
      "Epoch 4/100\n",
      "5408/5408 [==============================] - 168s 31ms/step - loss: 0.5532 - accuracy: 0.7341\n",
      "Epoch 5/100\n",
      "5408/5408 [==============================] - 168s 31ms/step - loss: 0.5503 - accuracy: 0.7333\n",
      "Epoch 6/100\n",
      "3498/5408 [==================>...........] - ETA: 58s - loss: 0.5528 - accuracy: 0.7306"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-a4a912877400>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m           \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m           \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m          )\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "if 'GRU_predict_v10_2_1.h5' in os.listdir('./'):\n",
    "    model = load_model(\"./GRU_predict_v10_2_1.h5\")\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='accuracy', \n",
    "        patience=30\n",
    "    ),\n",
    "    # 保存模型\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'GRU_predict_v10_2_1.h5', \n",
    "    monitor='loss', \n",
    "    save_best_only=True),\n",
    "    \n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', \n",
    "        factor=0.8,\n",
    "        patience=5, \n",
    "        mode='auto',\n",
    "        min_lr=0.00003)\n",
    "]\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', #continu together\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy']\n",
    "             \n",
    "             )\n",
    "\n",
    "model.fit(x=[combin_train_data1,combin_train_data2,combin_train_data3],\n",
    "          y=combin_target_data,\n",
    "          batch_size=36,\n",
    "          epochs=100,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          class_weight=class_weight,\n",
    "          callbacks=callbacks_list \n",
    "         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v_10_2_1 收敛效果好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n",
    "\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D,Convolution1D,MaxPooling1D, Flatten, Dense, Concatenate,Dropout\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "true_stand_data=np.load(r'.//data3//true_array.npy')\n",
    "false_stand_data=np.load(r'.//data3//false_array.npy')\n",
    "\n",
    "true_stand_data=true_stand_data[:-100,:,:,:]\n",
    "false_stand_data=false_stand_data[:-100,:,:,:]\n",
    "\n",
    "true_stand_data=true_stand_data[:,:,:,0]\n",
    "false_stand_data=false_stand_data[:,:,:,0]\n",
    "\n",
    "sample_num={'true_num':true_stand_data.shape[0],'false_num':false_stand_data.shape[0]}\n",
    "class_weight = {\n",
    "                0: (1 / sample_num['false_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2,\n",
    "                1: (1 / sample_num['true_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2\n",
    "                }\n",
    "\n",
    "true_sample_channel_1 = []\n",
    "true_sample_channel_2 = []\n",
    "true_sample_channel_3 = []\n",
    "\n",
    "false_sample_channel_1 = []\n",
    "false_sample_channel_2 = []\n",
    "false_sample_channel_3 = []\n",
    "\n",
    "\n",
    "for sample_number in range(true_stand_data.shape[0]):\n",
    "    true_sample_channel_1.append(copy.deepcopy(true_stand_data[sample_number,:,1]))\n",
    "    true_sample_channel_2.append(copy.deepcopy(true_stand_data[sample_number,:,2]))\n",
    "    true_sample_channel_3.append(copy.deepcopy(true_stand_data[sample_number,:,6]))\n",
    "    \n",
    "for sample_number in range(false_stand_data.shape[0]):\n",
    "    false_sample_channel_1.append(copy.deepcopy(false_stand_data[sample_number,:,1]))\n",
    "    false_sample_channel_2.append(copy.deepcopy(false_stand_data[sample_number,:,2]))\n",
    "    false_sample_channel_3.append(copy.deepcopy(false_stand_data[sample_number,:,6]))\n",
    "    \n",
    "combin_train_data1 = np.concatenate((true_sample_channel_1,false_sample_channel_1),axis=0)\n",
    "combin_train_data2 = np.concatenate((true_sample_channel_2,false_sample_channel_2),axis=0)\n",
    "combin_train_data3 = np.concatenate((true_sample_channel_3,false_sample_channel_3),axis=0)\n",
    "\n",
    "combin_target_data= np.concatenate((np.ones((sample_num['true_num'],1)),np.zeros((sample_num['false_num'],1))),axis=0)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "combin_target_data=ohe.fit_transform(combin_target_data).toarray()    \n",
    "    \n",
    "    \n",
    "# Model 1\n",
    "in_1 = Input(shape=(110,1))\n",
    "C_1 = Convolution1D(filters=12,kernel_size=3,input_shape=(110,1),padding='same')(in_1)\n",
    "C_1 = Convolution1D(filters=12,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "C_1 = Convolution1D(filters=24,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = Convolution1D(filters=24,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "C_1 = Convolution1D(filters=48,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = Convolution1D(filters=48,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "C_1 = Convolution1D(filters=96,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = Convolution1D(filters=96,kernel_size=3,padding='same')(C_1)\n",
    "# C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "# C_1 = Flatten()(C_1)\n",
    "\n",
    "# # Model 1\n",
    "in_2 = Input(shape=(110,1))\n",
    "C_2 = Convolution1D(filters=12,kernel_size=3,input_shape=(110,1),padding='same')(in_2)\n",
    "C_2 = Convolution1D(filters=12,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "\n",
    "C_2 = Convolution1D(filters=24,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = Convolution1D(filters=24,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "\n",
    "C_2 = Convolution1D(filters=48,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = Convolution1D(filters=48,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "\n",
    "C_2 = Convolution1D(filters=96,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = Convolution1D(filters=96,kernel_size=3,padding='same')(C_2)\n",
    "# C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "# C_2 = Flatten()(C_2)\n",
    "\n",
    "in_3 = Input(shape=(110,1))\n",
    "C_3 = Convolution1D(filters=12,kernel_size=3,input_shape=(110,1),padding='same')(in_3)\n",
    "C_3 = Convolution1D(filters=12,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "\n",
    "C_3 = Convolution1D(filters=24,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = Convolution1D(filters=24,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "\n",
    "C_3 = Convolution1D(filters=48,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = Convolution1D(filters=48,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "\n",
    "C_3 = Convolution1D(filters=96,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = Convolution1D(filters=96,kernel_size=3,padding='same')(C_3)\n",
    "# C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "# C_3 = Flatten()(C_3)\n",
    "\n",
    "x_middle_concat = Concatenate(axis=-1)([C_1,C_2,C_3])\n",
    "\n",
    "x_middle_concat = GRU(units=288,return_sequences=True)(x_middle_concat)\n",
    "x_middle_concat = GRU(units=100)(x_middle_concat)\n",
    "# x_middle_concat = Dense(100, activation='tanh')(x_middle_concat)\n",
    "# x_middle_concat = Flatten()(x_middle_concat)\n",
    "model_final_dense_out = Dense(2, activation='softmax')(x_middle_concat)\n",
    "\n",
    "\n",
    "model = Model(inputs=[in_1,in_2,in_3], outputs=model_final_dense_out)\n",
    "print(model.summary())\n",
    "\n",
    "    \n",
    "    \n",
    "import os\n",
    "if 'GRU_predict_v10_2_1.h5' in os.listdir('./'):\n",
    "    model = load_model(\"./GRU_predict_v10_2_1.h5\")\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', \n",
    "        patience=20\n",
    "    ),\n",
    "    # 保存模型\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'GRU_predict_v10_2_1.h5', \n",
    "    monitor='val_loss', \n",
    "    save_best_only=True),\n",
    "    \n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', \n",
    "        factor=0.9,\n",
    "        patience=20, \n",
    "        mode='auto',\n",
    "        min_lr=0.00003)\n",
    "]\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', #continu together\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy']\n",
    "             \n",
    "             )\n",
    "\n",
    "model.fit(x=[combin_train_data1,combin_train_data2,combin_train_data3],\n",
    "          y=combin_target_data,\n",
    "          batch_size=360,\n",
    "          epochs=300,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          class_weight=class_weight,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_split=0.2\n",
    "         )\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n",
    "\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D,Convolution1D,MaxPooling1D, Flatten, Dense, Concatenate,Dropout\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "true_stand_data=np.load(r'.//data3//true_array.npy')\n",
    "false_stand_data=np.load(r'.//data3//false_array.npy')\n",
    "\n",
    "true_stand_data=true_stand_data[:-100,:,:,:]\n",
    "false_stand_data=false_stand_data[:-100,:,:,:]\n",
    "\n",
    "true_stand_data=true_stand_data[:,:,:,0]\n",
    "false_stand_data=false_stand_data[:,:,:,0]\n",
    "\n",
    "sample_num={'true_num':true_stand_data.shape[0],'false_num':false_stand_data.shape[0]}\n",
    "class_weight = {\n",
    "                0: (1 / sample_num['false_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2,\n",
    "                1: (1 / sample_num['true_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2\n",
    "                }\n",
    "\n",
    "true_sample_channel_1 = []\n",
    "true_sample_channel_2 = []\n",
    "true_sample_channel_3 = []\n",
    "\n",
    "false_sample_channel_1 = []\n",
    "false_sample_channel_2 = []\n",
    "false_sample_channel_3 = []\n",
    "\n",
    "\n",
    "for sample_number in range(true_stand_data.shape[0]):\n",
    "    true_sample_channel_1.append(copy.deepcopy(true_stand_data[sample_number,:,1]))\n",
    "    true_sample_channel_2.append(copy.deepcopy(true_stand_data[sample_number,:,2]))\n",
    "    true_sample_channel_3.append(copy.deepcopy(true_stand_data[sample_number,:,6]))\n",
    "    \n",
    "for sample_number in range(false_stand_data.shape[0]):\n",
    "    false_sample_channel_1.append(copy.deepcopy(false_stand_data[sample_number,:,1]))\n",
    "    false_sample_channel_2.append(copy.deepcopy(false_stand_data[sample_number,:,2]))\n",
    "    false_sample_channel_3.append(copy.deepcopy(false_stand_data[sample_number,:,6]))\n",
    "    \n",
    "combin_train_data1 = np.concatenate((true_sample_channel_1,false_sample_channel_1),axis=0)\n",
    "combin_train_data2 = np.concatenate((true_sample_channel_2,false_sample_channel_2),axis=0)\n",
    "combin_train_data3 = np.concatenate((true_sample_channel_3,false_sample_channel_3),axis=0)\n",
    "\n",
    "combin_target_data= np.concatenate((np.ones((sample_num['true_num'],1)),np.zeros((sample_num['false_num'],1))),axis=0)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "combin_target_data=ohe.fit_transform(combin_target_data).toarray()    \n",
    "    \n",
    "    \n",
    "# Model 1\n",
    "in_1 = Input(shape=(110,1))\n",
    "C_1 = Convolution1D(filters=55,kernel_size=3,input_shape=(110,1),padding='same')(in_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "C_1 = Convolution1D(filters=22,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "C_1 = Convolution1D(filters=10,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "# # Model 1\n",
    "in_2 = Input(shape=(110,1))\n",
    "C_2 = Convolution1D(filters=55,kernel_size=3,input_shape=(110,1),padding='same')(in_2)\n",
    "C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "\n",
    "C_2 = Convolution1D(filters=22,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "\n",
    "C_2 = Convolution1D(filters=10,kernel_size=3,padding='same')(C_2)\n",
    "C_2 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_2)\n",
    "\n",
    "\n",
    "in_3 = Input(shape=(110,1))\n",
    "C_3 = Convolution1D(filters=55,kernel_size=3,input_shape=(110,1),padding='same')(in_3)\n",
    "C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "\n",
    "C_3 = Convolution1D(filters=22,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "\n",
    "C_3 = Convolution1D(filters=10,kernel_size=3,padding='same')(C_3)\n",
    "C_3 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_3)\n",
    "\n",
    "x_middle_concat = Concatenate(axis=-1)([C_1,C_2,C_3])\n",
    "# x_middle_concat = GRU(units=100)(x_middle_concat)\n",
    "# model_final_dense_out = Dense(2, activation='softmax')(x_middle_concat)\n",
    "model_final_dense_out = GRU(units=2,activation='softmax')(x_middle_concat)\n",
    "\n",
    "model = Model(inputs=[in_1,in_2,in_3], outputs=model_final_dense_out)\n",
    "print(model.summary())\n",
    "\n",
    "    \n",
    "    \n",
    "import os\n",
    "if 'GRU_predict_v10_2_2.h5' in os.listdir('./'):\n",
    "    model = load_model(\"./GRU_predict_v10_2_2.h5\")\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='accuracy', \n",
    "        patience=20\n",
    "    ),\n",
    "    # 保存模型\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'GRU_predict_v10_2_2.h5', \n",
    "    monitor='loss', \n",
    "    save_best_only=True),\n",
    "    \n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', \n",
    "        factor=0.9,\n",
    "        patience=20, \n",
    "        mode='auto',\n",
    "        min_lr=0.00003)\n",
    "]\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', #continu together\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy']\n",
    "             \n",
    "             )\n",
    "\n",
    "model.fit(x=[combin_train_data1,combin_train_data2,combin_train_data3],\n",
    "          y=combin_target_data,\n",
    "          batch_size=360,\n",
    "          epochs=300,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          class_weight=class_weight,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_split=0.2\n",
    "         )\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n",
    "\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D,Convolution1D,MaxPooling1D, Flatten, Dense, Concatenate,Dropout\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "true_stand_data=np.load(r'.//data3//true_array.npy')\n",
    "false_stand_data=np.load(r'.//data3//false_array.npy')\n",
    "\n",
    "true_stand_data=true_stand_data[:-100,:,:,:]\n",
    "false_stand_data=false_stand_data[:-100,:,:,:]\n",
    "\n",
    "true_stand_data=true_stand_data[:,:,:,0]\n",
    "false_stand_data=false_stand_data[:,:,:,0]\n",
    "\n",
    "sample_num={'true_num':true_stand_data.shape[0],'false_num':false_stand_data.shape[0]}\n",
    "class_weight = {\n",
    "                0: (1 / sample_num['false_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2,\n",
    "                1: (1 / sample_num['true_num'] * (sample_num['true_num'] + sample_num['false_num'])) / 2\n",
    "                }\n",
    "\n",
    "true_sample_channel_1 = []\n",
    "\n",
    "false_sample_channel_1 = []\n",
    "\n",
    "\n",
    "\n",
    "for sample_number in range(true_stand_data.shape[0]):\n",
    "    true_sample_channel_1.append(copy.deepcopy(true_stand_data[sample_number][:,[1,2,6]]))\n",
    "    \n",
    "for sample_number in range(false_stand_data.shape[0]):\n",
    "    false_sample_channel_1.append(copy.deepcopy(false_stand_data[sample_number][:,[1,2,6]]))\n",
    "    \n",
    "combin_train_data1 = np.concatenate((true_sample_channel_1,false_sample_channel_1),axis=0)\n",
    "\n",
    "combin_target_data= np.concatenate((np.ones((sample_num['true_num'],1)),np.zeros((sample_num['false_num'],1))),axis=0)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "combin_target_data=ohe.fit_transform(combin_target_data).toarray()    \n",
    "    \n",
    "    \n",
    "# Model 1\n",
    "in_1 = Input(shape=(110,3))\n",
    "C_1 = Convolution1D(filters=28,kernel_size=3,input_shape=(110,3),padding='same')(in_1)\n",
    "C_1 = Convolution1D(filters=28,kernel_size=3,padding='same')(in_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "C_1 = Convolution1D(filters=56,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = Convolution1D(filters=56,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "C_1 = Convolution1D(filters=112,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = Convolution1D(filters=112,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "C_1 = Convolution1D(filters=224,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = Convolution1D(filters=224,kernel_size=3,padding='same')(C_1)\n",
    "C_1 = MaxPooling1D(pool_size=2,strides=2, padding='valid')(C_1)\n",
    "\n",
    "x_middle_concat = Flatten()(C_1)\n",
    "# x_middle_concat = GRU(units=100)(x_middle_concat)\n",
    "model_final_dense_out = Dense(2, activation='softmax')(x_middle_concat)\n",
    "\n",
    "\n",
    "model = Model(inputs=in_1, outputs=model_final_dense_out)\n",
    "print(model.summary())\n",
    "\n",
    "    \n",
    "    \n",
    "import os\n",
    "if 'GRU_predict_v10_2_3.h5' in os.listdir('./'):\n",
    "    model = load_model(\"./GRU_predict_v10_2_3.h5\")\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='accuracy', \n",
    "        patience=20\n",
    "    ),\n",
    "    # 保存模型\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath = 'GRU_predict_v10_2_3.h5', \n",
    "    monitor='loss',\n",
    "    save_best_only=True),\n",
    "    \n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', \n",
    "        factor=0.9,\n",
    "        patience=10, \n",
    "        mode='auto',\n",
    "        min_lr=0.00003)\n",
    "]\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', #continu together\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy']\n",
    "             \n",
    "             )\n",
    "\n",
    "model.fit(x=combin_train_data1,\n",
    "          y=combin_target_data,\n",
    "          batch_size=360,\n",
    "          epochs=300,\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          class_weight=class_weight,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_split=0.2\n",
    "         )\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
